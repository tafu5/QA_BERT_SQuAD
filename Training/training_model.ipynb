{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD Model based on BERT\n",
    "\n",
    "In this project, I will train a SQuAD model based on the BERT architecture. The goal is to fine-tune a pre-trained BERT model on the SQuAD (Stanford Question Answering Dataset) to enable it to answer questions based on a given context.\n",
    "\n",
    "**Overview of the Training Process:**\n",
    "\n",
    "Model: We will be using the base version of BERT, specifically bert-base-uncased, which is one of the most popular variants of the BERT architecture. The base version of BERT has 12 layers (transformer blocks), 12 attention heads, and a total of 110 million parameters. \n",
    "\n",
    "**Dataset:** \n",
    "\n",
    "The SQuAD dataset, a widely used benchmark for training and evaluating question-answering models, will be used in this project. SQuAD contains over 100,000 question-answer pairs, where each question is paired with a specific passage from which the answer can be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Current Directory\n",
    "current_directory = os.getcwd()\n",
    "# Save the Data Path\n",
    "data_path = os.path.join(current_directory, 'Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Loading the Bert Tokenizer which is specifically designed for tokenizing text data in a way that aligns with the BERT model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Loading the Bert Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab\n",
    "\n",
    "Get the vocabulary used for train the Bert Model, it's necessary to process the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the VOCAB from BERT\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Save the vocab as txr\n",
    "with open(os.path.join(data_path, \"vocab.txt\"), \"w\", encoding='utf-8') as file:\n",
    "    for token, index in vocab.items():\n",
    "        file.write(f\"{token}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  generate_tf_record_from_json_file converts the SQuAD training data and the vocabulary into a TFRecord format, which is a format commonly used in TensorFlow for efficient data storage and input pipeline processing. \n",
    "\n",
    "\n",
    "max_seq_length = 384: Defines the maximum sequence length for each input example. The sequences (comprising tokens) that exceed this length will be truncated, and shorter sequences will be padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.data.squad_lib import generate_tf_record_from_json_file\n",
    "\n",
    "# Convert train data and vocab into a TFRecord format\n",
    "input_meta_data = generate_tf_record_from_json_file(\n",
    "    input_file_path = os.path.join(data_path, \"train-v1.1.json\"),      # training data\n",
    "    vocab_file_path = os.path.join(data_path, \"vocab.txt\"),            # vocabulary\n",
    "    output_path     = os.path.join(data_path, \"train-v1.1.tf_record\"), # output file name\n",
    "    max_seq_length  = 384\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_squad_dataset method is used to construct a training dataset for a BERT-based model using the SQuAD data, which has been previously converted into TFRecord format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.legacy.bert.input_pipeline import create_squad_dataset \n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Max Secuence (Max number of tokens for context + question) in the training data\n",
    "max_seq_len = input_meta_data['max_seq_length']\n",
    "\n",
    "# Construction of the training dataset\n",
    "dataset = create_squad_dataset(\n",
    "    file_path   = os.path.join(data_path, \"train-v1.1.tf_record\"),\n",
    "    seq_length  = max_seq_len,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    is_training = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom function to split the dataset into training and validation data.\n",
    "- To simplify the training cycle, 1500 batches (6000 samples) will be used\n",
    "- The split is 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, nb_batches, train_prop):\n",
    "    # Number of training batches\n",
    "    NB_BATCHES_TRAIN = int(nb_batches * train_prop)\n",
    "    # Number of validation batches\n",
    "    NB_BATCHES_VAL = int(nb_batches - NB_BATCHES_TRAIN)\n",
    "    # Trainig and Validation datasets\n",
    "    train_dataset = dataset.take(NB_BATCHES_TRAIN)\n",
    "    val_dataset = dataset.skip(NB_BATCHES_VAL).take(NB_BATCHES_VAL)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "NB_BATCHES = 1500\n",
    "TRAIN_PROP = 0.8\n",
    "\n",
    "NB_BATCHES_TRAIN = int(NB_BATCHES * TRAIN_PROP)\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset=dataset, nb_batches=NB_BATCHES, train_prop=TRAIN_PROP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "For constructing the model, I will use a pre-trained BERT model as the initial layer. The final layer of the model will output two tensors: the first tensor will contain the start_logits, and the second tensor will contain the end_logits. These logits represent the predicted start and end positions for each word in the context, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BertSquadLayer\n",
    "Construction of the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BertSquadLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BertSquadLayer, self).__init__()\n",
    "        # Final Dense Layer to get the logit for each word in the sentence to be the start and end sentence position \n",
    "        self.final_dense = tf.keras.layers.Dense(\n",
    "              units = 2,\n",
    "              kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev=0.02)) # Initializate the Params \n",
    "    \n",
    "    def call(self, inputs):\n",
    "      # Pass throught the final dense the output of the Bert Model \n",
    "      logits = self.final_dense(inputs) # (batch_size, seq_len, 2)\n",
    "    \n",
    "      # Reshape the logits (the first dim is 2, the firstone for the start position and the second one for the end position)\n",
    "      logits = tf.transpose(logits, [2, 0, 1]) # (2, batch_size, seq_len)\n",
    "    \n",
    "      # Unstack the logits\n",
    "      unstacked_logits = tf.unstack(logits, axis = 0) # [(batch_size, seq_len), (batch_size, seq_len)]\n",
    "      \n",
    "      return unstacked_logits[0], unstacked_logits[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTSquad\n",
    "\n",
    "Is the complete SQuAD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TFBertModel\n",
    "\n",
    "class BERTSquad(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 name=\"bert_squad\"):\n",
    "        super(BERTSquad, self).__init__(name=name)\n",
    "\n",
    "        # Create the Bert Layer\n",
    "        self.bert_layer  = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        # Final Dense\n",
    "        self.squad_layer = BertSquadLayer()\n",
    "\n",
    "    def apply_bert(self, inputs):\n",
    "        # Obtain Bert Output\n",
    "        output = self.bert_layer([inputs[\"input_word_ids\"],\n",
    "                                  inputs[\"input_mask\"],\n",
    "                                  inputs[\"input_type_ids\"]])\n",
    "        \n",
    "        # Obtain the attention for each word in the context\n",
    "        sequence_output = output.last_hidden_state\n",
    "        \n",
    "        return sequence_output\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply the bert layer to the input\n",
    "        seq_output = self.apply_bert(inputs)\n",
    "        # Get the logits for each context-word after apply the squad_layer layer \n",
    "        start_logits, end_logits = self.squad_layer(seq_output)\n",
    "\n",
    "        return start_logits, end_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Instance of the Bert Model\n",
    "bert_squad = BERTSquad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp import optimization\n",
    "\n",
    "# Set the learning rate and the warmup stems\n",
    "INIT_LR = 5e-5\n",
    "WARMUP_STEPS = int((NB_BATCHES_TRAIN) * 0.1)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr          = INIT_LR,\n",
    "    num_train_steps  = NB_BATCHES_TRAIN,\n",
    "    num_warmup_steps = WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "The `squad_loss_fn` function calculates the loss for the SQuAD model.\n",
    "\n",
    "Finally, the `loss` metric is initialized to keep track of the average loss during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def squad_loss_fn(input, model_outputs):\n",
    "    # Get the start and end position\n",
    "    start_positions = input['start_positions']\n",
    "    end_positions = input['end_positions']\n",
    "    \n",
    "    # Get the model output \n",
    "    start_logits, end_logits = model_outputs\n",
    "\n",
    "    # Calculate the loss for the start and end position\n",
    "    start_loss = tf.keras.backend.sparse_categorical_crossentropy(\n",
    "        start_positions, start_logits, from_logits = True)   #from_logits = True. Indica que la salida del modelo no es una probabilidad\n",
    "    \n",
    "    end_loss = tf.keras.backend.sparse_categorical_crossentropy(\n",
    "        end_positions, end_logits, from_logits = True)\n",
    "\n",
    "    # get the final loss\n",
    "    # reduce_mean: Calculate the mean loss of the start and end tensors\n",
    "    total_loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# Initialize the loss\n",
    "loss = tf.keras.metrics.Mean(name = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "bert_squad.compile(optimizer,\n",
    "                   squad_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the time between epochs\n",
    "def epoch_time(start, end):\n",
    "    elapsed_time = end - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    time = f'{hours}h {minutes}m {seconds}s'\n",
    "    \n",
    "    return time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, model, loss):\n",
    "\n",
    "    loss.reset_state()\n",
    "\n",
    "    for (inputs, targets) in test_data:\n",
    "\n",
    "        model_outputs = model(inputs, training=False)\n",
    "        test_loss = squad_loss_fn(targets, model_outputs)\n",
    "\n",
    "        loss.update_state(test_loss)\n",
    "    \n",
    "    return loss.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom trainer to train the SQuAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(n_epochs, train_data, model, loss, val_data=None):\n",
    "    import time\n",
    "\n",
    "    # Training and Validation loss lists\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []    \n",
    "\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Inicio del Epoch {epoch+1}\\n\")\n",
    "        \n",
    "        # Get the initial time for the epoch\n",
    "        start = time.time()\n",
    "        # Restore accumulated loss\n",
    "        loss.reset_state()\n",
    "        \n",
    "        for (batch, (inputs, targets)) in enumerate(train_data):\n",
    "            \n",
    "            # Compute the gradients\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Get the output and loss\n",
    "                model_outputs = model(inputs, training=True)\n",
    "                train_loss_batch = squad_loss_fn(targets, model_outputs)\n",
    "\n",
    "            # Calculate gradients and update parameters\n",
    "            gradients = tape.gradient(train_loss_batch, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # Train loss update\n",
    "            loss.update_state(train_loss_batch)\n",
    "            # Get the final time for the epoch\n",
    "            end = time.time()\n",
    "\n",
    "            # Print results every 50 batches\n",
    "            if (batch % 50 == 0) & (batch != 0):\n",
    "                \n",
    "                print(f\"\"\"Batch {batch:4} | Train: Loss {loss.result():.4f}\"\"\")\n",
    "\n",
    "        print(\"\")\n",
    "        # Get the current training loss \n",
    "        train_loss = loss.result().numpy()\n",
    "        print(f\"Tiempo total para entrenar la epoch {epoch+1}: {epoch_time(start, end)}\\n \")\n",
    "        print(f\"\"\"- Train: Loss {train_loss:5.4f}\"\"\")\n",
    "\n",
    "        # Restore the loss\n",
    "        loss.reset_state()\n",
    "\n",
    "        # Evaluate the model in the validation dataset\n",
    "        if val_data is not None:\n",
    "            val_loss = evaluate(val_data, model, loss)\n",
    "            print(f\"\"\"- Val: Loss {val_loss:5.4f}\"\"\")\n",
    "            print(\"\")\n",
    "            print(f\"-----\" * 5)\n",
    "            val_loss_list.append(val_loss)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "    if val_data is not None:\n",
    "        return train_loss_list, val_loss_list\n",
    "    else:\n",
    "        return train_loss_list, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train the model for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del Epoch 1\n",
      "\n",
      "Batch   50 | Train: Loss 5.7525\n",
      "Batch  100 | Train: Loss 5.0917\n",
      "Batch  150 | Train: Loss 4.4206\n",
      "Batch  200 | Train: Loss 3.9761\n",
      "Batch  250 | Train: Loss 3.6454\n",
      "Batch  300 | Train: Loss 3.4034\n",
      "Batch  350 | Train: Loss 3.2752\n",
      "Batch  400 | Train: Loss 3.1275\n",
      "Batch  450 | Train: Loss 2.9635\n",
      "Batch  500 | Train: Loss 2.8342\n",
      "Batch  550 | Train: Loss 2.7228\n",
      "Batch  600 | Train: Loss 2.6434\n",
      "Batch  650 | Train: Loss 2.5663\n",
      "Batch  700 | Train: Loss 2.4961\n",
      "Batch  750 | Train: Loss 2.4346\n",
      "Batch  800 | Train: Loss 2.3804\n",
      "Batch  850 | Train: Loss 2.3368\n",
      "Batch  900 | Train: Loss 2.2837\n",
      "Batch  950 | Train: Loss 2.2381\n",
      "Batch 1000 | Train: Loss 2.1865\n",
      "Batch 1050 | Train: Loss 2.1396\n",
      "Batch 1100 | Train: Loss 2.0965\n",
      "Batch 1150 | Train: Loss 2.0518\n",
      "\n",
      "Tiempo total para entrenar la epoch 1: 3h 9m 36s\n",
      " \n",
      "- Train: Loss 2.0122\n",
      "- Val: Loss 0.6834\n",
      "\n",
      "-------------------------\n",
      "Inicio del Epoch 2\n",
      "\n",
      "Batch   50 | Train: Loss 1.4100\n",
      "Batch  100 | Train: Loss 1.3054\n",
      "Batch  150 | Train: Loss 1.1690\n",
      "Batch  200 | Train: Loss 1.1315\n",
      "Batch  250 | Train: Loss 1.1009\n",
      "Batch  300 | Train: Loss 1.0558\n",
      "Batch  350 | Train: Loss 1.0762\n",
      "Batch  400 | Train: Loss 1.0359\n",
      "Batch  450 | Train: Loss 0.9896\n",
      "Batch  500 | Train: Loss 0.9697\n",
      "Batch  550 | Train: Loss 0.9448\n",
      "Batch  600 | Train: Loss 0.9257\n",
      "Batch  650 | Train: Loss 0.9149\n",
      "Batch  700 | Train: Loss 0.9047\n",
      "Batch  750 | Train: Loss 0.8916\n",
      "Batch  800 | Train: Loss 0.8842\n",
      "Batch  850 | Train: Loss 0.8865\n",
      "Batch  900 | Train: Loss 0.8858\n",
      "Batch  950 | Train: Loss 0.8804\n",
      "Batch 1000 | Train: Loss 0.8676\n",
      "Batch 1050 | Train: Loss 0.8620\n",
      "Batch 1100 | Train: Loss 0.8581\n",
      "Batch 1150 | Train: Loss 0.8570\n",
      "\n",
      "Tiempo total para entrenar la epoch 2: 2h 52m 33s\n",
      " \n",
      "- Train: Loss 0.8696\n",
      "- Val: Loss 0.6753\n",
      "\n",
      "-------------------------\n",
      "Inicio del Epoch 3\n",
      "\n",
      "Batch   50 | Train: Loss 1.1876\n",
      "Batch  100 | Train: Loss 1.2744\n",
      "Batch  150 | Train: Loss 1.1740\n",
      "Batch  200 | Train: Loss 1.1691\n",
      "Batch  250 | Train: Loss 1.1201\n",
      "Batch  300 | Train: Loss 1.0604\n",
      "Batch  350 | Train: Loss 1.0923\n",
      "Batch  400 | Train: Loss 1.0488\n",
      "Batch  450 | Train: Loss 1.0008\n",
      "Batch  500 | Train: Loss 0.9821\n",
      "Batch  550 | Train: Loss 0.9608\n",
      "Batch  600 | Train: Loss 0.9446\n",
      "Batch  650 | Train: Loss 0.9353\n",
      "Batch  700 | Train: Loss 0.9243\n",
      "Batch  750 | Train: Loss 0.9028\n",
      "Batch  800 | Train: Loss 0.8976\n",
      "Batch  850 | Train: Loss 0.8942\n",
      "Batch  900 | Train: Loss 0.8895\n",
      "Batch  950 | Train: Loss 0.8884\n",
      "Batch 1000 | Train: Loss 0.8755\n",
      "Batch 1050 | Train: Loss 0.8673\n",
      "Batch 1100 | Train: Loss 0.8624\n",
      "Batch 1150 | Train: Loss 0.8667\n",
      "\n",
      "Tiempo total para entrenar la epoch 3: 3h 9m 34s\n",
      " \n",
      "- Train: Loss 0.8744\n",
      "- Val: Loss 0.6882\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set the logger of TensorFlow to avoid warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "NB_EPOCHS = 2\n",
    "\n",
    "train_results, val_results = trainer(n_epochs   = NB_EPOCHS,\n",
    "                                     train_data = train_dataset, \n",
    "                                     model      = bert_squad,\n",
    "                                     loss       = loss,\n",
    "                                     val_data   = val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Saving\n",
    "\n",
    "This section of the code ensures that the directory structure for saving the model exists and then saves the model's weights to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as bert_layer_call_fn, bert_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 424). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Create the model path\n",
    "model_path = \"Model/tf2/tensorflow/1\"\n",
    "# Get the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# A Model foldel will be created if doesn't exist\n",
    "if 'Model' not in os.listdir(parent_directory):\n",
    "    os.makedirs(os.path.join(parent_directory, model_path))\n",
    "\n",
    "# Save SQuAD Model\n",
    "bert_squad.save(os.path.join(parent_directory, model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "\n",
    "In this section, I will test the model using the SQuAD validation dataset to evaluate its performance. Specifically, we will use the `dev-v1.1.json` file, which is the SQuAD validation set containing 10,570 examples. \n",
    "\n",
    "The process involves the following steps:\n",
    "1. **Load the Testing Dataset**: We read and parse the `dev-v1.1.json` file to obtain the examples that will be used for evaluation.\n",
    "2. **Model Prediction**: The model, which was trained on the SQuAD training set, will generate predictions on these examples.\n",
    "3. **Evaluation Metrics**: I will then calculate performance metrics such as Exact Match (EM) and F1 score to assess how well the model's predictions match the ground truth answers in the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the testing samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.data.squad_lib import read_squad_examples\n",
    "\n",
    "# Read the all examples\n",
    "all_examples = read_squad_examples(\n",
    "    input_file  = os.path.join(data_path, \"dev-v1.1.json\"),   # Testing dataset file\n",
    "    is_training = False,                                     \n",
    "    version_2_with_negative = False)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation fo the TFrecord file to store the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.data.squad_lib import FeatureWriter\n",
    "\n",
    "# Create the Features in the TFRecord eval file (now it's empty)\n",
    "eval_writer = FeatureWriter(\n",
    "    filename    = os.path.join(data_path, \"eval.tf_record\"), # path and name where the TFRecord is saved\n",
    "    is_training = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method 'convert_examples_to_features' converts the samples into a features to be processed and ready to use for| the SQuAD model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.data.squad_lib import convert_examples_to_features\n",
    "\n",
    "# Function to append features in the eval_writer TFRecord file\n",
    "# If the feature has padding will be added into eval_writer. Otherwise into the all_features\n",
    "\n",
    "def _append_feature(feature, is_padding):\n",
    "    if not is_padding:\n",
    "        all_features.append(feature)\n",
    "    eval_writer.process_feature(feature)\n",
    "\n",
    "BATCH_SIZE_VAL = 4\n",
    "\n",
    "all_features = []\n",
    "\n",
    "dataset_size = convert_examples_to_features(\n",
    "    examples         = all_examples,                       # Input examples to convert in Features \n",
    "    tokenizer        = tokenizer,                          # Tokenizer to process the examples\n",
    "    max_seq_length   = input_meta_data['max_seq_length'],  # Max input seq len\n",
    "    doc_stride       = 128,                                # doc_stride=128 to split the secuences longer than max_seq_len every 128 tokens\n",
    "    max_query_length = 64,                                 # Max query lenght\n",
    "    is_training      = False,                              # Is no training\n",
    "    output_fn        = _append_feature,                    # Function to save or process the Features\n",
    "    batch_size       = BATCH_SIZE_VAL)                                  \n",
    "\n",
    "eval_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch size for testing is 2709\n"
     ]
    }
   ],
   "source": [
    "# Get the number of batches for the Testing Dataset\n",
    "NB_BATCHES_TEST = dataset_size // BATCH_SIZE_VAL\n",
    "\n",
    "print(f\"The batch size for testing is {NB_BATCHES_TEST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "# Create the eval dataset from the TFRecord eval file\n",
    "eval_dataset = create_squad_dataset(\n",
    "    file_path   = os.path.join(data_path, \"eval.tf_record\"), # path where the TFRecord is saved \n",
    "    seq_length  = input_meta_data['max_seq_length'],         # Max seq lenght\n",
    "    batch_size  = BATCH_SIZE,                                          \n",
    "    is_training = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code is used to process model predictions and store the results in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/2709\n",
      " 100/2709\n",
      " 200/2709\n",
      " 300/2709\n",
      " 400/2709\n",
      " 500/2709\n",
      " 600/2709\n",
      " 700/2709\n",
      " 800/2709\n",
      " 900/2709\n",
      "1000/2709\n",
      "1100/2709\n",
      "1200/2709\n",
      "1300/2709\n",
      "1400/2709\n",
      "1500/2709\n",
      "1600/2709\n",
      "1700/2709\n",
      "1800/2709\n",
      "1900/2709\n",
      "2000/2709\n",
      "2100/2709\n",
      "2200/2709\n",
      "2300/2709\n",
      "2400/2709\n",
      "2500/2709\n",
      "2600/2709\n",
      "2700/2709\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Create a named tuple collection\n",
    "RawResult = collections.namedtuple(\"RawResult\",\n",
    "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])\n",
    "\n",
    "# Create a function to store the tokens and logits in RawResult\n",
    "def get_raw_results(predictions):\n",
    "    for unique_ids, start_logits, end_logits in zip(predictions['unique_ids'],\n",
    "                                                    predictions['start_logits'],\n",
    "                                                    predictions['end_logits']):\n",
    "        yield RawResult(\n",
    "            unique_id    = unique_ids.numpy(),\n",
    "            start_logits = start_logits.numpy().tolist(),\n",
    "            end_logits   = end_logits.numpy().tolist())\n",
    "\n",
    "# Create all_results list to append the tokens and logits\n",
    "all_results = []\n",
    "for count, inputs in enumerate(eval_dataset):\n",
    "    x, _ = inputs\n",
    "    # Delete the ids from the input 'x'\n",
    "    unique_ids = x.pop(\"unique_ids\")\n",
    "    # Get the logits from the squad bert model\n",
    "    start_logits, end_logits = bert_squad(x, training=False)\n",
    "\n",
    "    # Save results in a dictionary\n",
    "    output_dict = dict(\n",
    "        unique_ids   = unique_ids,\n",
    "        start_logits = start_logits,\n",
    "        end_logits   = end_logits\n",
    "    )\n",
    "\n",
    "    # Append results in the all_results list\n",
    "    for result in get_raw_results(output_dict):\n",
    "        all_results.append(result)\n",
    "    if count % 100 == 0:\n",
    "        print(f\"{count:4}/{NB_BATCHES_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.data.squad_lib import write_predictions\n",
    "\n",
    "# Output file for the predictions\n",
    "output_prediction_file    = os.path.join(data_path, \"predictions.json\")\n",
    "# Output with the number of best answers\n",
    "output_nbest_file         = os.path.join(data_path, \"nbest_predictions.json\")\n",
    "# Output file for the null log odds\n",
    "output_null_log_odds_file = os.path.join(data_path, \"null_odds.json\")\n",
    "\n",
    "# Write the predictions into a JSON file\n",
    "write_predictions(\n",
    "    all_examples = all_examples,                              # Raw sample (question + context)\n",
    "    all_features = all_features,                              # Features (tokens, attention_mask, type_id)\n",
    "    all_results  = all_results,                               # logits\n",
    "    n_best_size  = 20,                                        # number of best answers\n",
    "    max_answer_length = 30,                                   # Max lenght of the answer\n",
    "    do_lower_case = True,                                     # Convert text to lower\n",
    "    output_prediction_file = output_prediction_file,          # Save prediction JSON file\n",
    "    output_nbest_file  = output_nbest_file,                   # Save n best answer for each question\n",
    "    output_null_log_odds_file = output_null_log_odds_file,    # Save the probability of  don't answer\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"exact_match\": 62.87606433301798, \"f1\": 73.38428365761662}\n"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "!python ./Data/evaluate-v1.1.py ./Data/dev-v1.1.json ./Data/predictions.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
